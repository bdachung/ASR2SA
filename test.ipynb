{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdc8a40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from datasets import load_metric\n",
    "import datasets\n",
    "from transformers import (Wav2Vec2ForCTC, Wav2Vec2Processor,Wav2Vec2CTCTokenizer, \n",
    "                          Wav2Vec2FeatureExtractor, AutoTokenizer, AutoModelForSequenceClassification)\n",
    "from ctcdecode import CTCBeamDecoder\n",
    "import os\n",
    "from ipywebrtc import AudioRecorder, CameraStream\n",
    "import soundfile as sf\n",
    "import librosa \n",
    "import IPython.display as ipd\n",
    "from IPython.display import HTML, display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9076aa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a809b4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Wav2Vec2CTCTokenizer(\n",
    "    \"./ASR_vocab/vocab.json\", unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\")\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor()\n",
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2abe93e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=processor.tokenizer.convert_ids_to_tokens(range(0, processor.tokenizer.vocab_size))\n",
    "space_ix = vocab.index('|')\n",
    "vocab[space_ix]=' '\n",
    "\n",
    "ctcdecoder = CTCBeamDecoder(vocab, \n",
    "    model_path=os.path.join('kenlm_model/kenlm_vi', \"lm.binary\"),\n",
    "    alpha=1.2359788738676971,\n",
    "    beta=4.966395194796742,\n",
    "    cutoff_top_n=40,\n",
    "    cutoff_prob=1.0,\n",
    "    beam_width=100,\n",
    "    num_processes=4,\n",
    "    blank_id=processor.tokenizer.pad_token_id,\n",
    "    log_probs_input=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee806cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASR_model = Wav2Vec2ForCTC.from_pretrained(\"./ASR_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b3a291cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ASR_predict(wav_file):\n",
    "    ASR_model.to(\"cuda\")\n",
    "    sig, sr = librosa.load(wav_file, sr=16000)\n",
    "    sig = torch.flatten(torch.tensor(sig))\n",
    "    input_values = processor(sig.to(\"cuda\"),sampling_rate=16000,return_tensors=\"pt\").input_values.to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        logits = ASR_model(input_values).logits\n",
    "\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    return processor.batch_decode(pred_ids)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4d222e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ASR_predict_beam_search(wav_file):\n",
    "    ASR_model.to(\"cuda\")\n",
    "    sig, sr = librosa.load(wav_file, sr=16000)\n",
    "    sig = torch.flatten(torch.tensor(sig))\n",
    "    input_values = processor(sig.to(\"cuda\"),sampling_rate=16000,return_tensors=\"pt\").input_values.to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        logits = ASR_model(input_values).logits\n",
    "\n",
    "    beam_results, beam_scores, timesteps, out_lens = ctcdecoder.decode(logits)\n",
    "    return \"\".join(vocab[n] for n in beam_results[0][0][:out_lens[0][0]]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20c13f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "SA_tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3aec05d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SA_model = AutoModelForSequenceClassification.from_pretrained(\"./SA_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf98e7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SA_predict(text):\n",
    "    SA_model.to(\"cuda\")\n",
    "    input_values = SA_tokenizer(text,return_tensors=\"pt\").to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        logits = SA_model(**input_values).logits\n",
    "    result = torch.argmax(logits, dim=-1)\n",
    "    return result.item() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1efa029b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SA_predict(\"đừng bảo cảm_ơn mà bị chửi nếu đéo biết cái giải này nó trao để tôn_vinh đối_tượng như nào nha còn là nói_thẳng mấy con vô nói chỉ cảm_ơn mà bị chửi ấy thì là ngu thật là giả ngu vô kháy vài phát cảm_ơn teddy thì viết hoa tên ngta đàng_hoàng chút với cả lựa đúng bài mà vô_cảm ơn ha cmt ngu ngục đi kháy mà ko dám nhận bị ngta chửi kêu chỉ cảm_ơn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eaf4aaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = [\"CLEAN\", \"OFFENSIVE BUT NOT HATE\", \"HATE\"]\n",
    "def ASR2SA_predict(wav_file):\n",
    "    text = ASR_predict(wav_file)\n",
    "    print(\"text:\",text)\n",
    "    result = SA_predict(text.lower())\n",
    "    print(\"SA:\", dic[result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b86a23ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112b688d5f74489a8e0ee44960034d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AudioRecorder(audio=Audio(value=b'', format='webm'), stream=CameraStream(constraints={'audio': True, 'video': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "camera = CameraStream(constraints={'audio': True,'video':False})\n",
    "recorder = AudioRecorder(stream=camera)\n",
    "recorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "70a908ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: ANH THƯƠNG EM MÀ\n",
      "SA: CLEAN\n"
     ]
    }
   ],
   "source": [
    "with open('./temp/recording.webm', 'wb') as f:\n",
    "    f.write(recorder.audio.value)\n",
    "!ffmpeg -i './temp/recording.webm' -ac 1 -f wav './temp/file.wav' -y -hide_banner -loglevel panic\n",
    "ASR2SA_predict('./temp/file.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5809d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "STT",
   "language": "python",
   "name": "stt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
